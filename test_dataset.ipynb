{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/videomae/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset.datasets import VideoClsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path=\"/tsukimi/datasets/Chiba/cut_videos_2label\"\n",
    "# mapping_file=\"/tsukimi/datasets/Chiba/persistence/video_label_map_filtered.json\"\n",
    "folder_map=\"/tsukimi/datasets/Chiba/persistence/video_folder_map.pkl\"\n",
    "import json\n",
    "import os\n",
    "import os.path as op\n",
    "# with open(mapping_file) as f:\n",
    "#     label_map = json.load(f)\n",
    "\n",
    "import pickle\n",
    "with open(folder_map, 'rb') as f:\n",
    "    folder_map = pickle.load(f)\n",
    "    \n",
    "# video path like /tsukimi/datasets/Chiba/cut_videos_2label/6_S4_3T_RBG15_center.mov/restrainer_interaction-running-30.26-31.17.mov\n",
    "path_label_list=[]    \n",
    "\n",
    "for root, dirs, files in os.walk(video_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mov\"):\n",
    "            # parse the label\n",
    "            splits=file.split('-')\n",
    "            label0=splits[0]\n",
    "            label1=splits[1]\n",
    "            start=float(splits[2])\n",
    "            end=float(splits[3][:-4])\n",
    "            path_label_list.append((op.join(root, file), (label0, label1), (start, end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/tsukimi/datasets/Chiba/cut_videos_2label/8_S2_4T_RBG3_center.mov/running-running-141.09-142.0.mov', ('running', 'running'), (141.09, 142.0))\n"
     ]
    }
   ],
   "source": [
    "print(path_label_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map label set to 0~n\n",
    "label_map={}\n",
    "for i, label in enumerate(label_set):\n",
    "    label_map[label]=i\n",
    "\n",
    "for i, path_label in enumerate(path_label_list):\n",
    "    path, label=path_label.split()\n",
    "    label=label_map[label]\n",
    "    path_label_list[i]=' '.join([path, str(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_label_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train, temp\u001b[38;5;241m=\u001b[39mtrain_test_split(\u001b[43mpath_label_list\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     10\u001b[0m val, test\u001b[38;5;241m=\u001b[39mtrain_test_split(temp, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train),\u001b[38;5;28mlen\u001b[39m(val),\u001b[38;5;28mlen\u001b[39m(test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_label_list' is not defined"
     ]
    }
   ],
   "source": [
    "# # save path_label_list to csv file\n",
    "# import pandas as pd\n",
    "# df=pd.DataFrame(path_label_list)\n",
    "# df\n",
    "\n",
    "# train validation test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train, temp=train_test_split(path_label_list, test_size=0.3, random_state=42)\n",
    "val, test=train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(train),len(val),len(test))\n",
    "\n",
    "# check label distribution\n",
    "label_dict={}\n",
    "for filepath, label, _ in train:\n",
    "    for l in label:\n",
    "        label_dict[l]=label_dict.get(l, 0)+1\n",
    "print(label_dict)\n",
    "\n",
    "# save to csv\n",
    "# import pandas as pd\n",
    "df_train=pd.DataFrame(train)\n",
    "df_val=pd.DataFrame(val)\n",
    "df_test=pd.DataFrame(test)\n",
    "\n",
    "def encode_label(df):\n",
    "    df[1]=df[1].map(lambda labels:'&'.join(labels))\n",
    "    df.drop(columns=[2], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train=encode_label(df_train)\n",
    "df_val=encode_label(df_val)\n",
    "df_test=encode_label(df_test)\n",
    "save_path=\"/tsukimi/datasets/Chiba/baseline\"\n",
    "df_train.to_csv(op.join(save_path, 'train.csv'), index=False, header=False)\n",
    "df_val.to_csv(op.join(save_path, 'val.csv'), index=False, header=False)\n",
    "df_test.to_csv(op.join(save_path, 'test.csv'), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S3...</td>\n",
       "      <td>restrainer_interaction&amp;running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/3_S4...</td>\n",
       "      <td>unsupported_rearing&amp;idle_actions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/0_S3...</td>\n",
       "      <td>interaction_with_partner&amp;running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S1...</td>\n",
       "      <td>restrainer_interaction&amp;running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/6_S3...</td>\n",
       "      <td>climbing_on_side&amp;unsupported_rearing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  /tsukimi/datasets/Chiba/cut_videos_2label/1_S3...   \n",
       "1  /tsukimi/datasets/Chiba/cut_videos_2label/3_S4...   \n",
       "2  /tsukimi/datasets/Chiba/cut_videos_2label/0_S3...   \n",
       "3  /tsukimi/datasets/Chiba/cut_videos_2label/1_S1...   \n",
       "4  /tsukimi/datasets/Chiba/cut_videos_2label/6_S3...   \n",
       "\n",
       "                                      1  \n",
       "0        restrainer_interaction&running  \n",
       "1      unsupported_rearing&idle_actions  \n",
       "2      interaction_with_partner&running  \n",
       "3        restrainer_interaction&running  \n",
       "4  climbing_on_side&unsupported_rearing  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read train csv\n",
    "import pandas as pd\n",
    "df=pd.read_csv(op.join(save_path, 'train.csv'), header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.3759, -1.2759, -0.3759],\n",
      "        [-1.6803, -0.6803, -1.1803]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3759],\n",
       "        [-0.6803]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example logits and target\n",
    "x = torch.tensor([[0.1, 2.2, 3.1], [1.0, 2.0, 1.5]])  # logits for 2 samples, 3 classes each\n",
    "target = torch.tensor([2, 1])  # true class indices\n",
    "\n",
    "# Compute log_softmax\n",
    "logprobs = F.log_softmax(x, dim=-1)\n",
    "print(logprobs)\n",
    "# Gather the log probabilities of the actual classes\n",
    "selected_log_probs = logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "\n",
    "# Resulting tensor of selected log probabilities\n",
    "selected_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [1.0000, 0.0000, 0.0000]])\n",
      "Loss: 0.8683392405509949\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming the following mapping of labels to indices: A -> 0, B -> 1, C -> 2\n",
    "label_mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "\n",
    "# Example raw labels\n",
    "raw_labels = ['A&B', 'B&C', 'A&C','A&A']\n",
    "\n",
    "# Function to convert raw labels to one-hot encoded format\n",
    "def ground_truth_decoder(labels,num_classes=len(label_mapping)):\n",
    "    decoded = torch.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        parts = label.split('&')\n",
    "        for part in parts:\n",
    "            decoded[i, label_mapping[part]] += 1\n",
    "    return decoded/2\n",
    "\n",
    "# One-hot encoded targets\n",
    "targets = ground_truth_decoder(raw_labels)\n",
    "print(targets)\n",
    "# Example outputs from the model (logits)\n",
    "outputs = torch.randn(4, 3)  # Batch size of 3, and 3 classes\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion(outputs, targets)\n",
    "print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 0.0000, 1.0000]])\n",
      "tensor(0.8333)\n"
     ]
    }
   ],
   "source": [
    "from eventutils import multi_label_accuracy,custom_multi_label_pred,ground_truth_decoder\n",
    "import torch\n",
    "# Example outputs from the model (logits)\n",
    "outputs = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "# Example targets\n",
    "targets = torch.tensor([[0, 0.5, 0.5], [0.5, 0, 0.5], [0, 0, 1]])\n",
    "preds=custom_multi_label_pred(outputs)\n",
    "print(preds)\n",
    "acc=multi_label_accuracy(outputs, targets)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ground_truth_labels=[torch.Tensor([0, 1, 1]), torch.Tensor([1, 0, 1])]\n",
    "pred_labels=[torch.Tensor([1, 1, 1]), torch.Tensor([1, 0, 1])]\n",
    "ground_truth_labels=torch.cat(ground_truth_labels)\n",
    "pred_labels=torch.cat(pred_labels)\n",
    "confusion_matrix=multi_label_confusion_matrix(ground_truth_labels,pred_labels)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (TP, FP, FN, TN):\n",
      "tensor([[1., 0., 2.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/videomae/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def multi_label_confusion_matrix(ground_truth_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Calculate confusion matrix for multi-label classification.\n",
    "    Args:\n",
    "    - ground_truth_labels (torch.Tensor): ground truth binary labels where labels are considered present if non-zero.\n",
    "    - pred_labels (torch.Tensor): predicted binary labels, same shape as ground_truth_labels.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: Confusion matrix of shape (4, C) where C is the number of classes.\n",
    "      The rows represent TP, FP, FN, TN for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert probabilities to binary labels for confusion matrix calculation\n",
    "    ground_truth_labels = (ground_truth_labels > 0).float()\n",
    "    pred_labels = (pred_labels > 0).float()\n",
    "    \n",
    "    # Number of classes\n",
    "    num_classes = ground_truth_labels.shape[1]\n",
    "\n",
    "    # Initialize the confusion matrix components\n",
    "    TP = torch.zeros(num_classes)\n",
    "    FP = torch.zeros(num_classes)\n",
    "    FN = torch.zeros(num_classes)\n",
    "    TN = torch.zeros(num_classes)\n",
    "\n",
    "    # Calculate TP, FP, FN, TN for each class\n",
    "    for i in range(num_classes):\n",
    "        TP[i] = (ground_truth_labels[:, i] * pred_labels[:, i]).sum()\n",
    "        FP[i] = ((1 - ground_truth_labels[:, i]) * pred_labels[:, i]).sum()\n",
    "        FN[i] = (ground_truth_labels[:, i] * (1 - pred_labels[:, i])).sum()\n",
    "        TN[i] = ((1 - ground_truth_labels[:, i]) * (1 - pred_labels[:, i])).sum()\n",
    "\n",
    "    # Combine into a single confusion matrix\n",
    "    confusion_matrix = torch.stack((TP, FP, FN, TN))\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "# Example usage\n",
    "ground_truth_labels = torch.tensor([[0.5, 0.5, 0], [0, 0, 1], [0.5, 0, 0.5]])\n",
    "pred_labels = torch.tensor([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = multi_label_confusion_matrix(ground_truth_labels, pred_labels)\n",
    "print(\"Confusion Matrix (TP, FP, FN, TN):\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/2_S2...</td>\n",
       "      <td>restrainer_interaction&amp;immobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S2...</td>\n",
       "      <td>climbing_on_side&amp;immobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/9_S4...</td>\n",
       "      <td>immobility&amp;running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/2_S2...</td>\n",
       "      <td>running&amp;immobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/9_S1...</td>\n",
       "      <td>running&amp;immobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S3...</td>\n",
       "      <td>interaction_with_partner&amp;interaction_with_partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/8_S4...</td>\n",
       "      <td>interaction_with_partner&amp;interaction_with_partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/8_S3...</td>\n",
       "      <td>interaction_with_partner&amp;interaction_with_partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/0_S1...</td>\n",
       "      <td>interaction_with_partner&amp;interaction_with_partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/6_S2...</td>\n",
       "      <td>interaction_with_partner&amp;interaction_with_partner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0    /tsukimi/datasets/Chiba/cut_videos_2label/2_S2...   \n",
       "1    /tsukimi/datasets/Chiba/cut_videos_2label/1_S2...   \n",
       "2    /tsukimi/datasets/Chiba/cut_videos_2label/9_S4...   \n",
       "3    /tsukimi/datasets/Chiba/cut_videos_2label/2_S2...   \n",
       "4    /tsukimi/datasets/Chiba/cut_videos_2label/9_S1...   \n",
       "..                                                 ...   \n",
       "275  /tsukimi/datasets/Chiba/cut_videos_2label/1_S3...   \n",
       "276  /tsukimi/datasets/Chiba/cut_videos_2label/8_S4...   \n",
       "277  /tsukimi/datasets/Chiba/cut_videos_2label/8_S3...   \n",
       "278  /tsukimi/datasets/Chiba/cut_videos_2label/0_S1...   \n",
       "279  /tsukimi/datasets/Chiba/cut_videos_2label/6_S2...   \n",
       "\n",
       "                                                     1  \n",
       "0                    restrainer_interaction&immobility  \n",
       "1                          climbing_on_side&immobility  \n",
       "2                                   immobility&running  \n",
       "3                                   running&immobility  \n",
       "4                                   running&immobility  \n",
       "..                                                 ...  \n",
       "275  interaction_with_partner&interaction_with_partner  \n",
       "276  interaction_with_partner&interaction_with_partner  \n",
       "277  interaction_with_partner&interaction_with_partner  \n",
       "278  interaction_with_partner&interaction_with_partner  \n",
       "279  interaction_with_partner&interaction_with_partner  \n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"/tsukimi/datasets/Chiba/baseline/datalist/\"\n",
    "# read val.csv\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "df=pd.read_csv(op.join(path, 'val.csv'), header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels = torch.tensor([[0.5, 0.5, 0], [0, 0, 1], [0.5, 0, 0.5]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
