{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/videomae/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset.datasets import VideoClsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path=\"/tsukimi/datasets/Chiba/cut_videos_2label\"\n",
    "# mapping_file=\"/tsukimi/datasets/Chiba/persistence/video_label_map_filtered.json\"\n",
    "folder_map=\"/tsukimi/datasets/Chiba/persistence/video_folder_map.pkl\"\n",
    "import json\n",
    "import os\n",
    "import os.path as op\n",
    "# with open(mapping_file) as f:\n",
    "#     label_map = json.load(f)\n",
    "\n",
    "import pickle\n",
    "with open(folder_map, 'rb') as f:\n",
    "    folder_map = pickle.load(f)\n",
    "    \n",
    "# video path like /tsukimi/datasets/Chiba/cut_videos_2label/6_S4_3T_RBG15_center.mov/restrainer_interaction-running-30.26-31.17.mov\n",
    "path_label_list=[]    \n",
    "\n",
    "for root, dirs, files in os.walk(video_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mov\"):\n",
    "            # parse the label\n",
    "            splits=file.split('-')\n",
    "            label0=splits[0]\n",
    "            label1=splits[1]\n",
    "            start=float(splits[2])\n",
    "            end=float(splits[3][:-4])\n",
    "            path_label_list.append((op.join(root, file), (label0, label1), (start, end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/tsukimi/datasets/Chiba/cut_videos_2label/8_S2_4T_RBG3_center.mov/running-running-141.09-142.0.mov', ('running', 'running'), (141.09, 142.0))\n"
     ]
    }
   ],
   "source": [
    "print(path_label_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map label set to 0~n\n",
    "label_map={}\n",
    "for i, label in enumerate(label_set):\n",
    "    label_map[label]=i\n",
    "\n",
    "for i, path_label in enumerate(path_label_list):\n",
    "    path, label=path_label.split()\n",
    "    label=label_map[label]\n",
    "    path_label_list[i]=' '.join([path, str(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155 1748 1748\n",
      "{'restrainer_interaction': 5658, 'running': 7340, 'unsupported_rearing': 651, 'idle_actions': 356, 'interaction_with_partner': 1421, 'climbing_on_side': 666, 'immobility': 218}\n"
     ]
    }
   ],
   "source": [
    "# # save path_label_list to csv file\n",
    "# import pandas as pd\n",
    "# df=pd.DataFrame(path_label_list)\n",
    "# df\n",
    "\n",
    "# train validation test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train, temp=train_test_split(path_label_list, test_size=0.3, random_state=42)\n",
    "val, test=train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(train),len(val),len(test))\n",
    "\n",
    "# check label distribution\n",
    "label_dict={}\n",
    "for filepath, label, _ in train:\n",
    "    for l in label:\n",
    "        label_dict[l]=label_dict.get(l, 0)+1\n",
    "print(label_dict)\n",
    "\n",
    "# save to csv\n",
    "# import pandas as pd\n",
    "df_train=pd.DataFrame(train)\n",
    "df_val=pd.DataFrame(val)\n",
    "df_test=pd.DataFrame(test)\n",
    "\n",
    "def encode_label(df):\n",
    "    df[1]=df[1].map(lambda labels:'&'.join(labels))\n",
    "    df.drop(columns=[2], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train=encode_label(df_train)\n",
    "df_val=encode_label(df_val)\n",
    "df_test=encode_label(df_test)\n",
    "save_path=\"/tsukimi/datasets/Chiba/baseline\"\n",
    "df_train.to_csv(op.join(save_path, 'train.csv'), index=False, header=False)\n",
    "df_val.to_csv(op.join(save_path, 'val.csv'), index=False, header=False)\n",
    "df_test.to_csv(op.join(save_path, 'test.csv'), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S3...</td>\n",
       "      <td>restrainer_interaction&amp;running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/3_S4...</td>\n",
       "      <td>unsupported_rearing&amp;idle_actions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/0_S3...</td>\n",
       "      <td>interaction_with_partner&amp;running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S1...</td>\n",
       "      <td>restrainer_interaction&amp;running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/6_S3...</td>\n",
       "      <td>climbing_on_side&amp;unsupported_rearing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  /tsukimi/datasets/Chiba/cut_videos_2label/1_S3...   \n",
       "1  /tsukimi/datasets/Chiba/cut_videos_2label/3_S4...   \n",
       "2  /tsukimi/datasets/Chiba/cut_videos_2label/0_S3...   \n",
       "3  /tsukimi/datasets/Chiba/cut_videos_2label/1_S1...   \n",
       "4  /tsukimi/datasets/Chiba/cut_videos_2label/6_S3...   \n",
       "\n",
       "                                      1  \n",
       "0        restrainer_interaction&running  \n",
       "1      unsupported_rearing&idle_actions  \n",
       "2      interaction_with_partner&running  \n",
       "3        restrainer_interaction&running  \n",
       "4  climbing_on_side&unsupported_rearing  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read train csv\n",
    "import pandas as pd\n",
    "df=pd.read_csv(op.join(save_path, 'train.csv'), header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.3759, -1.2759, -0.3759],\n",
      "        [-1.6803, -0.6803, -1.1803]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3759],\n",
       "        [-0.6803]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example logits and target\n",
    "x = torch.tensor([[0.1, 2.2, 3.1], [1.0, 2.0, 1.5]])  # logits for 2 samples, 3 classes each\n",
    "target = torch.tensor([2, 1])  # true class indices\n",
    "\n",
    "# Compute log_softmax\n",
    "logprobs = F.log_softmax(x, dim=-1)\n",
    "print(logprobs)\n",
    "# Gather the log probabilities of the actual classes\n",
    "selected_log_probs = logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "\n",
    "# Resulting tensor of selected log probabilities\n",
    "selected_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [1.0000, 0.0000, 0.0000]])\n",
      "Loss: 0.8683392405509949\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming the following mapping of labels to indices: A -> 0, B -> 1, C -> 2\n",
    "label_mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "\n",
    "# Example raw labels\n",
    "raw_labels = ['A&B', 'B&C', 'A&C','A&A']\n",
    "\n",
    "# Function to convert raw labels to one-hot encoded format\n",
    "def ground_truth_decoder(labels,num_classes=len(label_mapping)):\n",
    "    decoded = torch.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        parts = label.split('&')\n",
    "        for part in parts:\n",
    "            decoded[i, label_mapping[part]] += 1\n",
    "    return decoded/2\n",
    "\n",
    "# One-hot encoded targets\n",
    "targets = ground_truth_decoder(raw_labels)\n",
    "print(targets)\n",
    "# Example outputs from the model (logits)\n",
    "outputs = torch.randn(4, 3)  # Batch size of 3, and 3 classes\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion(outputs, targets)\n",
    "print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 0.0000, 1.0000]])\n",
      "tensor(0.8333)\n"
     ]
    }
   ],
   "source": [
    "from eventutils import multi_label_accuracy,custom_multi_label_pred,ground_truth_decoder\n",
    "import torch\n",
    "# Example outputs from the model (logits)\n",
    "outputs = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "# Example targets\n",
    "targets = torch.tensor([[0, 0.5, 0.5], [0.5, 0, 0.5], [0, 0, 1]])\n",
    "preds=custom_multi_label_pred(outputs)\n",
    "print(preds)\n",
    "acc=multi_label_accuracy(outputs, targets)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
