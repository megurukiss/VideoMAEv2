{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/videomae/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset.datasets import VideoClsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path=\"/tsukimi/datasets/Chiba/cut_videos\"\n",
    "mapping_file=\"/tsukimi/datasets/Chiba/persistence/video_label_map_filtered.json\"\n",
    "folder_map=\"/tsukimi/datasets/Chiba/persistence/video_folder_map.pkl\"\n",
    "import json\n",
    "import os\n",
    "import os.path as op\n",
    "with open(mapping_file) as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "import pickle\n",
    "with open(folder_map, 'rb') as f:\n",
    "    folder_map = pickle.load(f)\n",
    "    \n",
    "path_label_list=[]    \n",
    "label_set=set()\n",
    "\n",
    "for video in label_map:\n",
    "    for eaf in label_map[video]:\n",
    "        eaf_name=eaf.split('/')[-1]\n",
    "        for clip in label_map[video][eaf]:\n",
    "            label=clip[0]\n",
    "            clip[1]=str(clip[1])\n",
    "            clip[2]=str(clip[2])\n",
    "            clip_name='_'.join(clip)+'.mov'\n",
    "            clip_path=op.join(video_path, video, eaf_name, clip_name)\n",
    "            path_label=' '.join([clip_path, label])\n",
    "            path_label_list.append(path_label)\n",
    "            label_set.add(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'restrainer_interaction': 0, 'unsupported_rearing': 1, 'running': 2, 'immobility': 3, 'idle_actions': 4, 'interaction_with_partner': 5, 'climbing_on_side': 6}\n"
     ]
    }
   ],
   "source": [
    "# map label set to 0~n\n",
    "label_map={}\n",
    "for i, label in enumerate(label_set):\n",
    "    label_map[label]=i\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map label set to 0~n\n",
    "label_map={}\n",
    "for i, label in enumerate(label_set):\n",
    "    label_map[label]=i\n",
    "\n",
    "for i, path_label in enumerate(path_label_list):\n",
    "    path, label=path_label.split()\n",
    "    label=label_map[label]\n",
    "    path_label_list[i]=' '.join([path, str(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save path_label_list to csv file\n",
    "# import pandas as pd\n",
    "# df=pd.DataFrame(path_label_list)\n",
    "# df\n",
    "\n",
    "# train validation test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test=train_test_split(path_label_list, test_size=0.2, random_state=42)\n",
    "train, val=train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "# save to csv\n",
    "import pandas as pd\n",
    "df_train=pd.DataFrame(train)\n",
    "df_val=pd.DataFrame(val)\n",
    "df_test=pd.DataFrame(test)\n",
    "\n",
    "save_path=\"/tsukimi/datasets/Chiba/baseline\"\n",
    "df_train.to_csv(op.join(save_path, 'train.csv'), index=False, header=False)\n",
    "df_val.to_csv(op.join(save_path, 'val.csv'), index=False, header=False)\n",
    "df_test.to_csv(op.join(save_path, 'test.csv'), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'reprob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[38;5;241m=\u001b[39m\u001b[43mVideoClsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43manno_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreprob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VideoMAEv2/dataset/datasets.py:57\u001b[0m, in \u001b[0;36mVideoClsDataset.__init__\u001b[0;34m(self, anno_path, data_root, mode, clip_len, frame_sample_rate, crop_size, short_side_size, new_height, new_width, keep_aspect_ratio, num_segment, num_crop, test_num_segment, test_num_crop, sparse_sample, args)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreprob\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrand_erase \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_loader \u001b[38;5;241m=\u001b[39m get_video_loader()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'reprob'"
     ]
    }
   ],
   "source": [
    "dataset=VideoClsDataset(anno_path=op.join(save_path, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.3759, -1.2759, -0.3759],\n",
      "        [-1.6803, -0.6803, -1.1803]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3759],\n",
       "        [-0.6803]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example logits and target\n",
    "x = torch.tensor([[0.1, 2.2, 3.1], [1.0, 2.0, 1.5]])  # logits for 2 samples, 3 classes each\n",
    "target = torch.tensor([2, 1])  # true class indices\n",
    "\n",
    "# Compute log_softmax\n",
    "logprobs = F.log_softmax(x, dim=-1)\n",
    "print(logprobs)\n",
    "# Gather the log probabilities of the actual classes\n",
    "selected_log_probs = logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "\n",
    "# Resulting tensor of selected log probabilities\n",
    "selected_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [1.0000, 0.0000, 0.0000]])\n",
      "Loss: 0.8683392405509949\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming the following mapping of labels to indices: A -> 0, B -> 1, C -> 2\n",
    "label_mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "\n",
    "# Example raw labels\n",
    "raw_labels = ['A&B', 'B&C', 'A&C','A&A']\n",
    "\n",
    "# Function to convert raw labels to one-hot encoded format\n",
    "def ground_truth_decoder(labels,num_classes=len(label_mapping)):\n",
    "    decoded = torch.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        parts = label.split('&')\n",
    "        for part in parts:\n",
    "            decoded[i, label_mapping[part]] += 1\n",
    "    return decoded/2\n",
    "\n",
    "# One-hot encoded targets\n",
    "targets = ground_truth_decoder(raw_labels)\n",
    "print(targets)\n",
    "# Example outputs from the model (logits)\n",
    "outputs = torch.randn(4, 3)  # Batch size of 3, and 3 classes\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion(outputs, targets)\n",
    "print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 0.0000, 1.0000]])\n",
      "tensor(0.8333)\n"
     ]
    }
   ],
   "source": [
    "from eventutils import multi_label_accuracy,custom_multi_label_pred,ground_truth_decoder\n",
    "import torch\n",
    "# Example outputs from the model (logits)\n",
    "outputs = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "# Example targets\n",
    "targets = torch.tensor([[0, 0.5, 0.5], [0.5, 0, 0.5], [0, 0, 1]])\n",
    "preds=custom_multi_label_pred(outputs)\n",
    "print(preds)\n",
    "acc=multi_label_accuracy(outputs, targets)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
